PROCESS ID:		3153407

DEVICE cuda:1 with 4 workers.

HYPERPARAMETER:
    	Epochs:	{NUM_EPOCHS}
    	Batch size:	{BATCH_SIZE}
    	Learning rate:	{LEARNING_RATE}
    
LOADING DATA ...
(✓) downloaded labeled data
(✓) loaded attack type data
(✓) fixed dtypes (int -> str) 
        with len =		9 
        with columns =	Index(['Attack Type', 'label', 'protocol_type', 'service', 'flag', 'land',
       'logged_in', 'is_host_login', 'is_guest_login'],
      dtype='object')
(✓) standardization of numerical values (mean = 0, std. dev. = 1)
(✓) one-hot encoded categorical columns
(✓) casted DataFrame into X, y (y is encoded)
(✓) casted X,y to TensorDataset
(✓) loaded data
-----------------
Epoch: 000/003 | Batch 0000/3860 | Loss: 102.6712 | KL: 1.1357 | RecLoss: -101.5356
Epoch: 000/003 | Batch 0500/3860 | Loss: 108.0278 | KL: 1.1046 | RecLoss: -106.9232
Epoch: 000/003 | Batch 1000/3860 | Loss: 111.0818 | KL: 1.0835 | RecLoss: -109.9983
Epoch: 000/003 | Batch 1500/3860 | Loss: 88.2705 | KL: 1.0532 | RecLoss: -87.2173
Epoch: 000/003 | Batch 2000/3860 | Loss: 96.5951 | KL: 1.0459 | RecLoss: -95.5492
Epoch: 000/003 | Batch 2500/3860 | Loss: 94.2650 | KL: 1.0290 | RecLoss: -93.2360
Epoch: 000/003 | Batch 3000/3860 | Loss: 85.2884 | KL: 1.0225 | RecLoss: -84.2659
Epoch: 000/003 | Batch 3500/3860 | Loss: 94.3330 | KL: 1.0296 | RecLoss: -93.3034
Time elapsed: 0.20 min
Epoch: 001/003 | Batch 0000/3860 | Loss: 89.4124 | KL: 1.0177 | RecLoss: -88.3947
Epoch: 001/003 | Batch 0500/3860 | Loss: 87.3599 | KL: 1.0141 | RecLoss: -86.3458
Epoch: 001/003 | Batch 1000/3860 | Loss: 84.8553 | KL: 1.0115 | RecLoss: -83.8439
Epoch: 001/003 | Batch 1500/3860 | Loss: 172.9226 | KL: 1.0143 | RecLoss: -171.9083
Epoch: 001/003 | Batch 2000/3860 | Loss: 92.1162 | KL: 1.0021 | RecLoss: -91.1141
Epoch: 001/003 | Batch 2500/3860 | Loss: 80.3158 | KL: 0.9863 | RecLoss: -79.3294
Epoch: 001/003 | Batch 3000/3860 | Loss: 79.8529 | KL: 0.9923 | RecLoss: -78.8606
Epoch: 001/003 | Batch 3500/3860 | Loss: 81.5694 | KL: 0.9823 | RecLoss: -80.5871
Time elapsed: 0.40 min
Epoch: 002/003 | Batch 0000/3860 | Loss: 73.4276 | KL: 0.9903 | RecLoss: -72.4373
Epoch: 002/003 | Batch 0500/3860 | Loss: 80.1913 | KL: 0.9849 | RecLoss: -79.2064
Epoch: 002/003 | Batch 1000/3860 | Loss: 71.8484 | KL: 0.9859 | RecLoss: -70.8625
Epoch: 002/003 | Batch 1500/3860 | Loss: 67.2768 | KL: 0.9825 | RecLoss: -66.2943
Epoch: 002/003 | Batch 2000/3860 | Loss: 62.1922 | KL: 0.9585 | RecLoss: -61.2337
Epoch: 002/003 | Batch 2500/3860 | Loss: 63.8118 | KL: 0.9769 | RecLoss: -62.8349
Epoch: 002/003 | Batch 3000/3860 | Loss: 81.0978 | KL: 0.9964 | RecLoss: -80.1014
Epoch: 002/003 | Batch 3500/3860 | Loss: 56.6731 | KL: 0.9850 | RecLoss: -55.6882
Time elapsed: 0.59 min
Total Training Time: 0.59 min
